{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Save2Drive](https://raw.githubusercontent.com/alahnala/AI4All2020-Michigan-NLP/master/slides/save2drive.png)\n",
    "\n",
    "# Language Translation\n",
    "\n",
    "In this project we will be teaching a model to translate from English to French. After you go through this notebook once, you can teach the model to translate from English to Spanish, German, or another language of your choice (just ask us in office hours!) or translate to English from any other language.\n",
    "\n",
    "Before we get started, here is an overview of how language works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"slides/overview.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"slides/overview2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"slides/encoder.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"slides/decoder.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"slides/detail_overview.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup - run\n",
    "import sys, os\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "  !rm -r Language_Translation\n",
    "  !git clone https://github.com/meera9397/LanguageTranslation.git\n",
    "  !cp -r Language_Translation/data/ .\n",
    "  !cp -r Language_Translation/slides/ .\n",
    "  !echo \"=== Files Copied ===\"\n",
    "from language_translation_help import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data Files\n",
    "\n",
    "The data for this project is a set of many thousands of English to French translation pairs. The file is a tab separated list of translation pairs:\n",
    "\n",
    "```\n",
    "I am cold.    J'ai froid.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make the translation easier, we perform several preprocessing steps, including \n",
    "* making all characters lowercase  --> .lower()\n",
    "* stripping white space --> .stri()\n",
    "* trim punctuation --> re.sub(r\"([.!?])\", r\" \\1\", s), re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "\n",
    "\n",
    "After you run through this notebook, you can come back here and play around with this cell. Think about the following questions when you do that:\n",
    "####  What would happen if you didn't lower case all the characters? \n",
    "####  What would happen if you didn't strip the lower case? \n",
    "#### What would happen if you removed things besides punctuation? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_string(s):\n",
    "    s = unicode_to_ascii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering sentences\n",
    "\n",
    "Since there are a *lot* of example sentences and we want to train something relatively quickly, we'll trim the data set to only relatively short and simple sentences. We're filtering to sentences that translate to the form \"I am\" or \"He is\" etc. (accounting for apostrophes being removed). \n",
    "\n",
    "After you go through this notebook, feel free to change these prefixes or add to them and see how that affects your model. You can look through the data files in the data folder and see which prefixes are used that are not included here for ideas on what to add in this section. Think about the following question when you do this:\n",
    "\n",
    "#### Why do you think we include contractions? (ex. \"i am\" as well as \"i m\"). Do you see a decrease or increase in the performance of the encoder and decoder when removing contractions?\n",
    "#### What are some other prefixes you chose to add/ remove here? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "good_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s\",\n",
    "    \"you are\", \"you re \"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have some functions to help us filter our data into sentences that have \"good prefixes.\" If you decide that you want to perform a translation from a language to English, you can change the variable english_to in the function below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_pair(p, good_prefixes):\n",
    "    # change the following variable from True to False if you want to translate a certain language TO English.\n",
    "    # This variable being True indicates that we are translating English into another language\n",
    "    english_to = True\n",
    "    if english_to == True:\n",
    "        return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "            p[0].startswith(good_prefixes)\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "            p[1].startswith(good_prefixes)\n",
    "\n",
    "def prepare_data(lang1_name, lang2_name, reverse=False):\n",
    "    input_lang, output_lang, pairs = read_langs(lang1_name, lang2_name, normalize_string, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filter_pairs(pairs, good_prefixes, filter_pair)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Indexing words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.index_words(pair[0])\n",
    "        output_lang.index_words(pair[1])\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we prepare our final data to input into our encoder and decoder using the \"prepare data\" function. It takes in 3 variables:\n",
    "* initial_lang: the language that we want to translate. We have set this as a default to 'eng', which is short for 'English.'\n",
    "* final_lang: the language that we want to translate to. We have set this as a default to 'fra', which is short for 'French\n",
    "* reverse: our data is set up in a certain way such that there is a natural translation order. For example, our text file on translating between English and French is called 'eng-fra.txt' meaning that the natural order would be to translate from english to French. Thus no reversing has to be done and reverse is by default, False. If we wanted to translate from French to English, we would set our initial_lang to 'fra', our final_lang to 'eng', and reverse to True'\n",
    "\n",
    "If you want to translate **from** French **to** English, set:\n",
    "* initial_lang = 'fra'\n",
    "* final_lang = 'eng'\n",
    "* reverse: True\n",
    "\n",
    "If you want to translate **from** English **to** Spanish, set:\n",
    "* initial_lang = 'eng'\n",
    "* final_lang = 'spa'\n",
    "* reverse: False\n",
    "\n",
    "If you want to translate **from** English **to** Spanish\n",
    "* initial_lang = 'spa'\n",
    "* final_lang = 'eng'\n",
    "* reverse: True\n",
    "\n",
    "If you want to translate **from** English **to** German\n",
    "* initial_lang = 'eng'\n",
    "* final_lang = 'deu'\n",
    "* reverse: False\n",
    "\n",
    "If you want to translate **from** English **to** German\n",
    "* initial_lang = 'deu'\n",
    "* final_lang = 'eng'\n",
    "* reverse: True\n",
    "\n",
    "#### This function outputs pairs of phrases in \"initial_lang\" and \"final_lang\", AKA the languages you want to translate from and to. We print an example pair at the end of the cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 177210 sentence pairs\n",
      "Trimmed to 11253 sentence pairs\n",
      "Indexing words...\n",
      "['i m not blushing !', 'je ne rougis pas !']\n"
     ]
    }
   ],
   "source": [
    "initial_lang = 'eng'\n",
    "final_lang = 'fra'\n",
    "reverse = False\n",
    "\n",
    "input_lang, output_lang, pairs = prepare_data(initial_lang, final_lang, reverse)\n",
    "\n",
    "# Print an example pair\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Testing the Encoder and Decoder\n",
    "The exact inputs and outputs are not exactly important for this cell. I just wanted you to get a little bit of intuition on how the encoders and decoders work. We start with a certain input, \"word_input\", initialize an encoder, \"encoder_test\", and run the encoder using both of those. We take the output of the encoder, \"all_encoder_outputs\", and put that into the decoder, along with the initialized decoder, \"decoder_test\", and the initial input to produce our final outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data3/home/meerak/LanguageTranslation/language_translation_help.py:189: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(attn_energies).unsqueeze(0).unsqueeze(0)\n",
      "/data3/home/meerak/LanguageTranslation/language_translation_help.py:253: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  output = F.log_softmax(self.out(torch.cat((rnn_output, context), 1)))\n"
     ]
    }
   ],
   "source": [
    "word_input = Variable(torch.LongTensor([1, 2, 3]))\n",
    "encoder_test = create_encoder()\n",
    "decoder_test =  create_decoder()\n",
    "\n",
    "all_encoder_outputs = run_encoder(encoder_test, word_input)\n",
    "_ = run_decoder(decoder_test, word_input, all_encoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Our Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"slides/training.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step to \"training\" is initializing our encoder and decoder. We do this in one step, and have it hidden in a helper function for ease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "all_vars_training = init_vars(input_lang, output_lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, **n_epochs** is the amount of time that we want to train for. A unit of time in this case is an \"epoch.\" After going through this file, you can play around with this number. Think about the following questions:\n",
    "#### Would increasing or decreasing n_epochs improve performance? Why?\n",
    "#### Do you notice a big difference in the translation ability of your encoder/decoder when you increase/decrease n_epochs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Configuring training\n",
    "n_epochs = 500\n",
    "plot_every = 200\n",
    "print_every = 100\n",
    "\n",
    "# Keep track of time elapsed and running averages\n",
    "start = time.time()\n",
    "plot_losses = []\n",
    "print_loss_total = 0 # Reset every print_every\n",
    "plot_loss_total = 0 # Reset every plot_every"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, we train our encoder and decoder! At each step, we compute a value called \"loss\", which is an indication of how bad our model is at language translation at the time (the higher the loss, the worse our model is at language translation). The loss should decrease over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data3/home/meerak/LanguageTranslation/language_translation_help.py:352: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(encoder.parameters(), clip)\n",
      "/data3/home/meerak/LanguageTranslation/language_translation_help.py:353: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(decoder.parameters(), clip)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 4s (- 8m 8s) (100 1%) 5.2268\n",
      "0m 10s (- 8m 25s) (200 2%) 3.6346\n",
      "0m 15s (- 8m 27s) (300 3%) 3.6203\n",
      "0m 20s (- 8m 11s) (400 4%) 3.3858\n",
      "0m 24s (- 7m 52s) (500 5%) 3.5507\n",
      "0m 30s (- 7m 57s) (600 6%) 3.5649\n",
      "0m 35s (- 7m 54s) (700 7%) 3.5139\n",
      "0m 41s (- 8m 0s) (800 8%) 3.8078\n",
      "0m 47s (- 8m 1s) (900 9%) 3.6309\n",
      "0m 52s (- 7m 55s) (1000 10%) 3.4949\n",
      "0m 58s (- 7m 55s) (1100 11%) 3.2284\n",
      "1m 4s (- 7m 55s) (1200 12%) 3.3863\n",
      "1m 11s (- 7m 56s) (1300 13%) 3.3993\n",
      "1m 17s (- 7m 56s) (1400 14%) 3.3985\n",
      "1m 23s (- 7m 53s) (1500 15%) 3.4245\n",
      "1m 29s (- 7m 49s) (1600 16%) 3.3926\n",
      "1m 35s (- 7m 45s) (1700 17%) 3.3626\n",
      "1m 41s (- 7m 40s) (1800 18%) 3.4642\n",
      "1m 46s (- 7m 35s) (1900 19%) 3.5025\n",
      "1m 53s (- 7m 32s) (2000 20%) 3.3451\n",
      "1m 58s (- 7m 24s) (2100 21%) 3.2737\n",
      "2m 3s (- 7m 17s) (2200 22%) 3.3376\n",
      "2m 7s (- 7m 8s) (2300 23%) 3.2352\n",
      "2m 14s (- 7m 5s) (2400 24%) 3.2364\n",
      "2m 20s (- 7m 0s) (2500 25%) 3.2909\n",
      "2m 26s (- 6m 56s) (2600 26%) 3.1601\n",
      "2m 31s (- 6m 50s) (2700 27%) 2.9886\n",
      "2m 37s (- 6m 45s) (2800 28%) 3.0917\n",
      "2m 43s (- 6m 40s) (2900 28%) 2.9418\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-72f41d807103>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Run the train function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_variable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_variable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_vars_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Keep track of loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data3/home/meerak/LanguageTranslation/language_translation_help.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_variable, target_variable, all_vars_train, max_length)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m     \u001b[0;31m# Backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data3/home/meerak/venv/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data3/home/meerak/venv/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Begin!\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    # Get phrase in language to translate from (input variable, default = English phrase) and\n",
    "    # phrase in language to translate to (target variable, default = French phrase)\n",
    "    training_pair = variables_from_pair(random.choice(pairs), input_lang, output_lang)\n",
    "    input_variable = training_pair[0]\n",
    "    target_variable = training_pair[1]\n",
    "\n",
    "    # Run the train function\n",
    "    loss = train(input_variable, target_variable, all_vars_training)\n",
    "\n",
    "    # Keep track of loss\n",
    "    print_loss_total += loss\n",
    "    plot_loss_total += loss\n",
    "\n",
    "    if epoch == 0: continue\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print_loss_avg = print_loss_total / print_every\n",
    "        print_loss_total = 0\n",
    "        print_summary = '%s (%d %d%%) %.4f' % (time_since(start, epoch / n_epochs), epoch, epoch / n_epochs * 100, print_loss_avg)\n",
    "        print(print_summary)\n",
    "        \n",
    "    if epoch % plot_every == 0:\n",
    "        plot_loss_avg = plot_loss_total / plot_every\n",
    "        plot_losses.append(plot_loss_avg)\n",
    "        plot_loss_total = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, you can see the loss decreasing over time, as our encoder and decoder get better at language translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def show_plot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    loc = ticker.MultipleLocator(base=0.2) # put ticks at regular intervals\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "\n",
    "show_plot(plot_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have trained our encoder and decoder, we can use them to perform translations! Below, in the \"evaluate_randomly\" function, we randomly pick a pair of phrases that we have trained on, and see how well we can translate that phrase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_evaluations = (input_lang, output_lang, all_vars_training[0], all_vars_training[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_randomly():\n",
    "    pair = random.choice(pairs)\n",
    "    output_words, decoder_attn = evaluate(pair[0], for_evaluations)\n",
    "    output_sentence = ' '.join(output_words)\n",
    "    \n",
    "    print('>', pair[0])\n",
    "    print('=', pair[1])\n",
    "    print('<', output_sentence)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can keep running this cell over and over again to see how well the translator does on various phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "evaluate_randomly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also evaluate the encoder/decoder on phrases that you come up with! Here is an example of how to do that. \n",
    "### Note\n",
    "The phrases you test have to start with the \"good prefixes\" and also contain words that the model has seen before. This is why you may get errors if you change the \"phrase\" below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase = 'i m happy .'\n",
    "output_words, _ = evaluate(phrase, for_evaluations)\n",
    "output_sentence = ' '.join(output_words)\n",
    "print('>', phrase)\n",
    "print('<', output_sentence)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
